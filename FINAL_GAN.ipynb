{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bMCgOAshnyt"
      },
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "from torchvision import transforms,models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "from ResNet import ResNet \n",
        "from loss_network import vgg\n",
        "from disc import Discriminator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7Ej3SZ40VN_"
      },
      "source": [
        "dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9qPhjb_hpt-",
        "outputId": "6f995f4f-3581-467b-ed50-4b54cc90cd00"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGyK6ZLjhnyz"
      },
      "source": [
        "class Model(object):\n",
        "\n",
        "    def __init__(self, image_size=256):\n",
        "        self.image_size = image_size\n",
        "        self.dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        self.transform_net = ResNet().to(self.dev)\n",
        "        self.loss_net = vgg().to(self.dev)\n",
        "        self.disc = Discriminator(self.image_size).to(self.dev)\n",
        "        self.loss_net.eval()\n",
        "\n",
        "\n",
        "    def load_dataset(self, dataset_path, style_img_path, batch_size=5):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        t = transforms.Compose([\n",
        "            transforms.Resize(self.image_size),\n",
        "            transforms.CenterCrop(self.image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda x : x.mul(255))\n",
        "        ])\n",
        "\n",
        "        data_folder = ImageFolder(dataset_path, transform=t)\n",
        "        self.contentloader = torch.utils.data.DataLoader(data_folder, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        stylefolder = ImageFolder(style_img_path, transform=t)\n",
        "        self.styleloader = torch.utils.data.DataLoader(stylefolder, batch_size=1, shuffle=True)\n",
        "\n",
        "\n",
        "    def vgg_normalize(self, x):\n",
        "        normalize = transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                                         std=(0.229, 0.224, 0.225))\n",
        "        x = x.div_(255.0)\n",
        "        out = normalize(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def gram_matrix(self, x):\n",
        "        (batch, ch, h, w) = x.size() \n",
        "        img = x.view(batch, ch, h*w)\n",
        "        img_transposed = img.transpose(1,2)\n",
        "        gram_matrix = img.bmm(img_transposed) / (ch * h * w)\n",
        "        return gram_matrix\n",
        "\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        if model_path != None : \n",
        "            self.transform_net.load_state_dict(torch.load(model_path, map_location=self.dev))\n",
        "\n",
        "\n",
        "    def train(self, epochs, style_weight, content_weight, disc_weight, lr, save_path=None, model_path=None, show_every=20, save_every=100):\n",
        "\n",
        "        self.mseloss = torch.nn.MSELoss()\n",
        "        self.bceloss = torch.nn.BCELoss()\n",
        "        self.opt = torch.optim.Adam(self.transform_net.parameters(), lr)\n",
        "        self.disc_opt = torch.optim.Adam(self.disc.parameters(), lr=0.0001)\n",
        "        self.load_model(model_path)\n",
        "\n",
        "        style_activation_list = []\n",
        "        style_images_list = []\n",
        "\n",
        "        for style_img, _ in self.styleloader : \n",
        "            style_images_list.append(style_img)\n",
        "            style_img = style_img.repeat(self.batch_size, 1, 1, 1)\n",
        "            style_activations = self.loss_net(self.vgg_normalize(style_img))\n",
        "            style_grams = [self.gram_matrix(y) for y in style_activations]\n",
        "            style_activation_list.append(style_grams)\n",
        "\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.transform_net.train()\n",
        "            print('EPOCH : ', epoch)\n",
        "\n",
        "            for batch_id, (img, _) in enumerate(self.contentloader):\n",
        "\n",
        "                for style_grams, style_image in zip(style_activation_list, style_images_list) : \n",
        "\n",
        "                    n_batch = len(img)\n",
        "                    \n",
        "                    img = img.to(self.dev)\n",
        "                    yhat = self.transform_net(img)\n",
        "\n",
        "                    disc_real_output = disc.forward(style_image)\n",
        "                    disc_fake_output = disc.forward(yhat)\n",
        "\n",
        "                    disc_real_loss = self.bceloss(disc_real_output, torch.ones_like(disc_real_output))\n",
        "                    disc_fake_loss = self.bceloss(disc_fake_output, torch.zeros_like(disc_fake_output))\n",
        "                    disc_loss = (disc_fake_loss + disc_real_loss)/2\n",
        "\n",
        "                    gen_real_loss = self.bceloss(disc_real_output, torch.zeros_like(disc_real_output))\n",
        "                    gen_fake_loss = self.bceloss(disc_fake_output, torch.ones_like(disc_fake_output))\n",
        "                    gen_loss = (gen_fake_loss + gen_real_loss)/2\n",
        "\n",
        "                    gen_loss *= disc_weight\n",
        "\n",
        "                    self.disc_opt.zero_grad()\n",
        "                    disc_loss.backward()\n",
        "                    self.disc_opt.step()\n",
        "\n",
        "                    yhat_normalized = self.vgg_normalize(yhat)\n",
        "                    content_normalized = self.vgg_normalize(img)\n",
        "\n",
        "                    yhat_activations = self.loss_net(yhat_normalized)\n",
        "                    content_activations = self.loss_net(content_normalized)\n",
        "\n",
        "                    content_loss = content_weight * self.mseloss(yhat_activations[0], content_activations[0])\n",
        "\n",
        "                    style_loss = 0\n",
        "                    for yhat, style_gram in zip(yhat_activations, style_grams):\n",
        "                        yhat_gram = self.gram_matrix(yhat)\n",
        "                        style_loss += self.mseloss(yhat_gram, style_gram[:n_batch , : , :])\n",
        "                    style_loss *= style_weight\n",
        "\n",
        "                    total_loss = style_loss + content_loss + gen_loss\n",
        "\n",
        "                    self.opt.zero_grad()\n",
        "                    total_loss.backward(retain_graph=True)\n",
        "                    self.opt.step()\n",
        "\n",
        "                if batch_id % show_every == 0 : \n",
        "                    print(f'Batch : {batch_id} | Content loss : {content_loss.item()} | Style loss : {style_loss.item()} | Total loss : {total_loss.item()}')\n",
        "\n",
        "                if batch_id % save_every == 0 : \n",
        "                    if save_path != None : \n",
        "                        torch.save(self.transform_net.state_dict(), save_path)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DfnFz6Yshnyz",
        "outputId": "70614875-a414-4208-ed2e-bd57e708f5f9"
      },
      "source": [
        "dataset_path = '/content/drive/MyDrive/EE/coco'\n",
        "style_img_path = '/content/drive/MyDrive/EE/styles/muse.jpg'\n",
        "EPOCHS = 10 \n",
        "CONTENT_WEIGHT = 1e5\n",
        "STYLE_WEIGHT = 1e9\n",
        "LR = 0.001\n",
        "SAVE_PATH = '/content/drive/MyDrive/EE/model.pt'\n",
        "MODEL_PATH = None\n",
        "\n",
        "model = Model()\n",
        "model.load_dataset(dataset_path=dataset_path, style_img_path=style_img_path)\n",
        "model.train(model_path=MODEL_PATH, epochs=EPOCHS, style_weight=STYLE_WEIGHT, content_weight=CONTENT_WEIGHT, lr=LR, save_path=SAVE_PATH, show_every=10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH :  0\n",
            "Batch : 0 | Content loss : 178605.140625 | Style loss : 14357277.0 | Total loss : 14535882.0\n",
            "Batch : 10 | Content loss : 179770.75 | Style loss : 11208544.0 | Total loss : 11388315.0\n",
            "Batch : 20 | Content loss : 169421.46875 | Style loss : 9406555.0 | Total loss : 9575976.0\n",
            "Batch : 30 | Content loss : 215300.671875 | Style loss : 8521484.0 | Total loss : 8736785.0\n",
            "Batch : 40 | Content loss : 221098.875 | Style loss : 7773263.5 | Total loss : 7994362.5\n",
            "Batch : 50 | Content loss : 243177.3125 | Style loss : 7166873.0 | Total loss : 7410050.5\n",
            "Batch : 60 | Content loss : 242279.796875 | Style loss : 6566985.5 | Total loss : 6809265.5\n",
            "Batch : 70 | Content loss : 289894.90625 | Style loss : 5574581.5 | Total loss : 5864476.5\n",
            "Batch : 80 | Content loss : 318673.8125 | Style loss : 4879651.0 | Total loss : 5198325.0\n",
            "Batch : 90 | Content loss : 279572.84375 | Style loss : 4338081.0 | Total loss : 4617654.0\n",
            "Batch : 100 | Content loss : 332152.4375 | Style loss : 3898925.75 | Total loss : 4231078.0\n",
            "Batch : 110 | Content loss : 328390.8125 | Style loss : 3580546.25 | Total loss : 3908937.0\n",
            "Batch : 120 | Content loss : 353711.0 | Style loss : 3426057.25 | Total loss : 3779768.25\n",
            "Batch : 130 | Content loss : 336584.15625 | Style loss : 3136597.25 | Total loss : 3473181.5\n",
            "Batch : 140 | Content loss : 364616.1875 | Style loss : 2999892.0 | Total loss : 3364508.25\n",
            "Batch : 150 | Content loss : 367325.28125 | Style loss : 2765685.5 | Total loss : 3133010.75\n",
            "Batch : 160 | Content loss : 341633.78125 | Style loss : 2630852.0 | Total loss : 2972485.75\n",
            "Batch : 170 | Content loss : 387949.375 | Style loss : 2523939.75 | Total loss : 2911889.0\n",
            "Batch : 180 | Content loss : 357605.5625 | Style loss : 2305472.25 | Total loss : 2663077.75\n",
            "Batch : 190 | Content loss : 383971.25 | Style loss : 2172014.0 | Total loss : 2555985.25\n",
            "Batch : 200 | Content loss : 394365.75 | Style loss : 2098251.25 | Total loss : 2492617.0\n",
            "Batch : 210 | Content loss : 402663.40625 | Style loss : 1965739.75 | Total loss : 2368403.25\n",
            "Batch : 220 | Content loss : 391917.125 | Style loss : 1910540.25 | Total loss : 2302457.5\n",
            "Batch : 230 | Content loss : 399788.53125 | Style loss : 1831563.125 | Total loss : 2231351.75\n",
            "Batch : 240 | Content loss : 368460.09375 | Style loss : 1759130.875 | Total loss : 2127591.0\n",
            "Batch : 250 | Content loss : 480557.78125 | Style loss : 1695706.875 | Total loss : 2176264.75\n",
            "Batch : 260 | Content loss : 427235.75 | Style loss : 1586397.125 | Total loss : 2013632.875\n",
            "Batch : 270 | Content loss : 400149.90625 | Style loss : 1542635.625 | Total loss : 1942785.5\n",
            "Batch : 280 | Content loss : 408487.03125 | Style loss : 1463804.625 | Total loss : 1872291.625\n",
            "Batch : 290 | Content loss : 404957.0 | Style loss : 1398103.75 | Total loss : 1803060.75\n",
            "Batch : 300 | Content loss : 419784.6875 | Style loss : 1298653.5 | Total loss : 1718438.25\n",
            "Batch : 310 | Content loss : 410658.96875 | Style loss : 1227857.0 | Total loss : 1638516.0\n",
            "Batch : 320 | Content loss : 436459.59375 | Style loss : 1177661.5 | Total loss : 1614121.125\n",
            "Batch : 330 | Content loss : 416327.375 | Style loss : 1155996.375 | Total loss : 1572323.75\n",
            "Batch : 340 | Content loss : 460703.53125 | Style loss : 1104273.0 | Total loss : 1564976.5\n",
            "Batch : 350 | Content loss : 421287.1875 | Style loss : 1085436.875 | Total loss : 1506724.0\n",
            "Batch : 360 | Content loss : 453599.6875 | Style loss : 1040100.3125 | Total loss : 1493700.0\n",
            "Batch : 370 | Content loss : 480995.9375 | Style loss : 966802.1875 | Total loss : 1447798.125\n",
            "Batch : 380 | Content loss : 460719.0 | Style loss : 912753.9375 | Total loss : 1373473.0\n",
            "Batch : 390 | Content loss : 462338.96875 | Style loss : 917690.875 | Total loss : 1380029.875\n",
            "Batch : 400 | Content loss : 456630.0 | Style loss : 818392.5 | Total loss : 1275022.5\n",
            "Batch : 410 | Content loss : 457940.0625 | Style loss : 808045.0625 | Total loss : 1265985.125\n",
            "Batch : 420 | Content loss : 456691.0625 | Style loss : 770262.75 | Total loss : 1226953.75\n",
            "Batch : 430 | Content loss : 437007.84375 | Style loss : 749021.8125 | Total loss : 1186029.625\n",
            "Batch : 440 | Content loss : 427335.6875 | Style loss : 760820.75 | Total loss : 1188156.5\n",
            "Batch : 450 | Content loss : 464882.03125 | Style loss : 688423.3125 | Total loss : 1153305.375\n",
            "Batch : 460 | Content loss : 429613.875 | Style loss : 670889.1875 | Total loss : 1100503.0\n",
            "Batch : 470 | Content loss : 467201.625 | Style loss : 646996.0625 | Total loss : 1114197.75\n",
            "Batch : 480 | Content loss : 458186.71875 | Style loss : 699697.3125 | Total loss : 1157884.0\n",
            "Batch : 490 | Content loss : 464274.46875 | Style loss : 632868.875 | Total loss : 1097143.375\n",
            "Batch : 500 | Content loss : 454191.40625 | Style loss : 633355.875 | Total loss : 1087547.25\n",
            "Batch : 510 | Content loss : 482625.625 | Style loss : 577460.4375 | Total loss : 1060086.0\n",
            "Batch : 520 | Content loss : 485953.34375 | Style loss : 579088.6875 | Total loss : 1065042.0\n",
            "Batch : 530 | Content loss : 477422.4375 | Style loss : 585246.8125 | Total loss : 1062669.25\n",
            "Batch : 540 | Content loss : 489617.6875 | Style loss : 578072.3125 | Total loss : 1067690.0\n",
            "Batch : 550 | Content loss : 449934.25 | Style loss : 532126.5625 | Total loss : 982060.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b71f3b0ba568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_img_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstyle_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTYLE_WEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONTENT_WEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAVE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-1c21ee8c7d18>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, style_weight, content_weight, lr, save_path, model_path, show_every, save_every)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EPOCH : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mn_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m    150\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}